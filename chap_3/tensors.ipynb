{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_storage(a,b): # function to check if two tensors have the same storage\n",
    "    return (a.storage().data_ptr() == b.storage().data_ptr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3: Tensors\n",
    "\n",
    "Deep learning systems derive meaning from data by extracting common attributes between different examples from the same class of data. This is done by first converting the input data into floating point numbers. In PyTorch we deal with floating point numbers using tensors.\n",
    "\n",
    "Tensors are multi-dimensional arrays and are the fundamental datastructures of PyTorch. While PyTorch tensors are the same as NumPy arrays, they have some added benefits as well:\n",
    "\n",
    "- We can perform very fast operations on them  on GPUs.\n",
    "\n",
    "- We can distribute operations on multiple devices/machines.\n",
    "\n",
    "- We can keep track of the computational graph that created them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Tensors: Multidimensional arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like a python list tensors are indexed the same way. We start by creating a tensor of specific size filled with 1s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above command creates a one-dimensional tensor of size 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1.])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the elements of the tensor using zero-based index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "for i in range(a.shape[0]):\n",
    "    print(a[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the elements inside our 1-d tensor are also tensors. To get just the value from these locations we use a[index].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(a.shape[0]):\n",
    "    print(a[i].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 Why use tensors and not lists\n",
    "\n",
    "Python lists an array of pointers that points to different python objects. These python objects are stored in different locations in the memory. The python objects in the list need not be of the same data type. While this makes python lists very flixible it also makes it inefficient. Lists require more memory to store the value of the pointers along with the value of the objects the pointer is pointing to. It also takes more time to perform operation on lists.\n",
    "\n",
    "Tensors on the otherhand like numpy arrays are contiguous blocks of memory. Tensors require lesser memory and performing numeric operations on them is also much faster. in deep learning we deal with huge volumes of data so being able to store them in small amounts of space and being able to perform operations on them really fast is very important. That is why we use tensors over python lists. \n",
    "\n",
    "While PyTorch tensors and NumPy arrays have almost the same benefits, we can store PyTorch tensors in GPUs in order to perform massively parallel, fast computations. We cannot do this with NumPy arrays. That is why we use PyTorch Tensors over NumPy arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Named tensors\n",
    "\n",
    "The dimensions (or axes) of our tensors usually index something like pixel locations or color channels. This means when we want to index into a tensor, we need to remember the ordering of the dimensions and write our indexing accordingly. As data is transformed through multiple tensors, keeping track of which dimension contains what data can be error-prone. To solve this we can add names to the dimensions. For the tensor operations where we pass dimensions as arguments, we can now pass the names as argument.\n",
    "\n",
    "*This feature is experimental*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1,  2,  3],\n",
      "         [ 4,  5,  6]],\n",
      "\n",
      "        [[ 7,  8,  9],\n",
      "         [10, 11, 12]]], names=('a', 'b', 'c'))\n",
      "torch.Size([2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "named_a = torch.tensor([[[1,2,3],[4,5,6]], [[7,8,9],[10,11,12]]], names=['a','b','c'])\n",
    "print(named_a)\n",
    "print(named_a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12], names=('ab',))\n",
      "torch.Size([12])\n"
     ]
    }
   ],
   "source": [
    "flat_named_a = named_a.flatten(['a','b','c'], 'ab')\n",
    "print(flat_named_a)\n",
    "print(flat_named_a.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor element types\n",
    "\n",
    "While creating a tensor, we can specify it's datatype using the dtype argument. The possible values of dtype arguments are:\n",
    "\n",
    "- torch.float32 or torch.float : 32-bit floating-point\n",
    "- torch.float64 or torch.double : 64-bit, double-precision floating-point\n",
    "- torch.float16 or torch.half : 16-bit, half-precision floating-point\n",
    "- torch.int8 : signed 8-bit integers\n",
    "- torch.uint8 : unsigned 8-bit integers\n",
    "- torch.int16 or torch.short : signed 16-bit integers\n",
    "- torch.int32 or torch.int : signed 32-bit integers\n",
    "- torch.int64 or torch.long : signed 64-bit integers\n",
    "- torch.bool : Boolean\n",
    "\n",
    "The default datatype for tensors is 32 bit floating-point.\n",
    "\n",
    "Creating tensors with integer as arguments will create a 64 bit integer tensor by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "torch.float32\n",
      "torch.float16\n"
     ]
    }
   ],
   "source": [
    "a_dt = torch.tensor([1,2,3,4]) # by default creates 64 bit integer tensor aka torch.LongTensor\n",
    "print(a_dt.dtype)\n",
    "b_dt = torch.tensor([1.,2.,3.,4.]) # by default creates 32 bit floating point\n",
    "print(b_dt.dtype)\n",
    "c_dt = torch.tensor([1.,2.,3.,4.],dtype=torch.float16)\n",
    "print(c_dt.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also assign datatypes to a tensor using the to methiod. The to method return a copy of the tensor with the dtype passed as argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int16\n"
     ]
    }
   ],
   "source": [
    "d_dt = a_dt.to(dtype=torch.short)\n",
    "print(d_dt.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 How tensors are stored in memory\n",
    "\n",
    "Values of tensors are allocated in contiguous chunks of memory managed by torch.Storage instances. A Storage is a one-dimensional array of numerical data that is a contiguous block of memory containing numbers of a given data type.\n",
    "\n",
    "A PyTorch tensor instance is a view of such a Storage instance that is capable of indexing into that storage using an offset and per-dimension strides.\n",
    "\n",
    "Multiple tensors can index the same storage even if they index into the data differently.\n",
    "![](img/storage.png)\n",
    "\n",
    "*Fig 1: Tensors are views of a storage instance. Source: Deep Learning with PyTorch. Section 3.7*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4.0\n",
      " 1.0\n",
      " 5.0\n",
      " 3.0\n",
      " 2.0\n",
      " 1.0\n",
      "[torch.FloatStorage of size 6]\n"
     ]
    }
   ],
   "source": [
    "points_storage = points.storage() # to access the storage of the points tensor\n",
    "print(points_storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A storage instance is always a 1-d array. if we modufy the values of the storage instance, it will also be reflected in the tensors that use that storage instance. in our example the points tensor uses the points_storage instance. if we modify the value of the points_storage instance, the value of the points tensor will change as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 1.],\n",
      "        [5., 3.],\n",
      "        [2., 1.]])\n",
      "tensor([[100.,   1.],\n",
      "        [  5.,   3.],\n",
      "        [  2.,   1.]])\n"
     ]
    }
   ],
   "source": [
    "print(points)\n",
    "points_storage[0] = 100\n",
    "print(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the operations on tensors introduced in the previous section, a small\n",
    "number of operations exist only as methods of the Tensor object. They are recogniz-\n",
    "able from a trailing underscore in their name, like zero_ , which indicates that the\n",
    "method operates in place by modifying the input instead of creating a new output tensor\n",
    "and returning it. For instance, the zero_ method zeros out all the elements of the input.\n",
    "Any method without the trailing underscore leaves the source tensor unchanged and\n",
    "instead returns a new tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[100.,   1.],\n",
      "        [  5.,   3.],\n",
      "        [  2.,   1.]])\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "print(points)\n",
    "points.zero_() \n",
    "print(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.8 Tensor metadata: Size, offset, and stride\n",
    "\n",
    "In order for the tensors to properly index into a storage instance, the tensors rely on: size, offset and stride. These things together with the storage helps us index the storage properly.\n",
    "\n",
    "**Size:** Tuple indicating how many elements across each dimension the tensor represents.\n",
    "\n",
    "**Storage offset:** The index in the storage corresponding to the first element in the tensor.\n",
    "\n",
    "**Stride:** A tuple indicating the number of elements in the storage that have to be\n",
    "skipped when the index is increased by 1 in each dimension.\n",
    "\n",
    "Accessing an element i, j in a 2D tensor results in accessing the storage_offset +\n",
    "stride[0] * i + stride[1] * j element in the storage.\n",
    "\n",
    "![](img/metadata.png)\n",
    "\n",
    "*Relationship between a tensor’s offset, size, and stride. Here the tensor is a view\n",
    "of a larger storage, like one that might have been allocated when creating a larger tensor. Source:  Deep Learning with PyTorch. Section: 3.8.* \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "tensor([4, 5, 6])\n",
      "3\n",
      "torch.Size([3])\n",
      "(3, 1)\n"
     ]
    }
   ],
   "source": [
    "a_temp = torch.tensor([[1,2,3],[4,5,6],[7,8,9]])\n",
    "print(a_temp)\n",
    "b_temp = a_temp[1]\n",
    "print(b_temp)\n",
    "print(b_temp.storage_offset())\n",
    "print(b_temp.size())\n",
    "print(a_temp.stride())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The connection between tensors and storage leads to some operations being really inexpensive like transpose or a subtensor, because they donot lead to a memory reallocation but creating a new tensor with a different offset and stride accessing the same storage.\n",
    "\n",
    "If we change the value of a tensor, the value is changed in it's storage and therefore the change will be reflected to all the other tensors accesing the same storage. If we donot want this we can clone the tensor/subtensor into a new tensor and make our changes there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_temp is:\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "b_temp is:\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "after changing b_temp, b_temp is: \n",
      "tensor([[2., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "after changing b_temp, a_temp is: \n",
      "tensor([[2., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_temp = torch.ones(3,3)\n",
    "print(\"a_temp is:\\n{}\".format(a_temp))\n",
    "b_temp = a_temp\n",
    "print(\"b_temp is:\\n{}\".format(b_temp))\n",
    "b_temp[0,0] = 2\n",
    "print(\"after changing b_temp, b_temp is: \\n{}\".format(b_temp))\n",
    "print(\"after changing b_temp, a_temp is: \\n{}\".format(a_temp))\n",
    "id(b_temp) == id(a_temp) # returns True is b_temp and a_temp points to the same storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c_temp is:\n",
      "tensor([[2., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "after changing c_temp, c_temp is: \n",
      "tensor([[100.,   1.,   1.],\n",
      "        [  1.,   1.,   1.],\n",
      "        [  1.,   1.,   1.]])\n",
      "after changing c_temp, a_temp is: \n",
      "tensor([[2., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_temp = a_temp.clone()\n",
    "print(\"c_temp is:\\n{}\".format(c_temp))\n",
    "c_temp[0,0] = 100\n",
    "print(\"after changing c_temp, c_temp is: \\n{}\".format(c_temp))\n",
    "print(\"after changing c_temp, a_temp is: \\n{}\".format(a_temp))\n",
    "id(c_temp) == id(a_temp) # returns True is c_temp and a_temp points to the same storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8.4 Contiguous tensors\n",
    "\n",
    "Some tensor operations in PyTorch only work on contiguous tensors. In that case, PyTorch will throw an informative exception and require us to call contiguous explicitly. It’s worth noting that\n",
    "calling contiguous will do nothing (and will not hurt performance) if the tensor is\n",
    "already contiguous. In our case, a_temp is contiguous, while if we transpose a_temp, it will not be contiguous as only the stride will change and therefore we will not be accessing the values of the storage contiguously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6225, 0.3725, 0.6758],\n",
      "        [0.5325, 0.8845, 0.8656],\n",
      "        [0.6403, 0.3875, 0.5479]])\n",
      "tensor([[0.6225, 0.5325, 0.6403],\n",
      "        [0.3725, 0.8845, 0.3875],\n",
      "        [0.6758, 0.8656, 0.5479]])\n",
      "True\n",
      "(3, 1)\n",
      "(1, 3)\n"
     ]
    }
   ],
   "source": [
    "a_temp = torch.rand(3,3)\n",
    "a_transpose = a_temp.transpose(0,1)\n",
    "print(a_temp)\n",
    "print(a_transpose)\n",
    "print(a_temp.stride())\n",
    "print(a_transpose.stride())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[99.0000,  0.5325,  0.6403],\n",
      "        [ 0.3725,  0.8845,  0.3875],\n",
      "        [ 0.6758,  0.8656,  0.5479]])\n",
      "tensor([[99.0000,  0.3725,  0.6758],\n",
      "        [ 0.5325,  0.8845,  0.8656],\n",
      "        [ 0.6403,  0.3875,  0.5479]])\n"
     ]
    }
   ],
   "source": [
    "a_transpose[0,0] = 99\n",
    "print(a_transpose)\n",
    "print(a_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[100.0000,   0.5325,   0.6403],\n",
      "        [  0.3725,   0.8845,   0.3875],\n",
      "        [  0.6758,   0.8656,   0.5479]])\n",
      "tensor([[0.6225, 0.3725, 0.6758],\n",
      "        [0.5325, 0.8845, 0.8656],\n",
      "        [0.6403, 0.3875, 0.5479]])\n"
     ]
    }
   ],
   "source": [
    "b_transpose = a_temp.clone()\n",
    "b_transpose = b_transpose.t()\n",
    "b_transpose[0,0]= 100\n",
    "print(b_transpose)\n",
    "print(a_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check if a tensor is contiguous or not using the is_contiguous method. If a tensor is not contiguous, the contiguous method returns a new tensor where the storage is contiguous for that tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_transpose.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_transpose.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 100.0\n",
       " 0.3725470304489136\n",
       " 0.6758251190185547\n",
       " 0.5325178503990173\n",
       " 0.8845298290252686\n",
       " 0.865615963935852\n",
       " 0.6403409242630005\n",
       " 0.38754844665527344\n",
       " 0.5479137301445007\n",
       "[torch.FloatStorage of size 9]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_transpose.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_cont = b_transpose.contiguous()\n",
    "b_cont.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 100.0\n",
       " 0.5325178503990173\n",
       " 0.6403409242630005\n",
       " 0.3725470304489136\n",
       " 0.8845298290252686\n",
       " 0.38754844665527344\n",
       " 0.6758251190185547\n",
       " 0.865615963935852\n",
       " 0.5479137301445007\n",
       "[torch.FloatStorage of size 9]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_cont.storage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3.9 Moving tensors to GPU\n",
    "\n",
    "PyTorch tensors can also be stored on GPUs to perform massively parallel, fast computations. In addition to dtype , a PyTorch Tensor also has the notion of device , which is where on the computer the tensor data is placed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_gpu = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]], device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created tensors on cpu can be copied to GPUs using the device argument in the to method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_temp = a_temp.to(device='cuda') # the to method creates a copy of the tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.10 Numpy interoperability\n",
    "\n",
    "PyTorch tensors can be converted to NumPy arrays and vice versa very efficiently. By doing so, we can take advantage of the huge swath of functionality in the wider Python ecosystem that has built up around the NumPy array type.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.ones(3, 4)\n",
    "points_np = points.numpy()\n",
    "points_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned numpy array shares the same underlying buffer with the tensor storage. This means any changes made to the numpy array will be reflected on the tensor as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.]]\n",
      "tensor([[10.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.]])\n"
     ]
    }
   ],
   "source": [
    "points_np[0,0]=10\n",
    "print(points_np)\n",
    "print(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[10.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.]])\n",
      "tensor([[20.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.]])\n",
      "[[20.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "points = torch.from_numpy(points_np)\n",
    "print(points)\n",
    "points[0,0]=20\n",
    "print(points)\n",
    "print(points_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.12 Saving tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.]])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save the points tensor using the following command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(points, 'points.t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can load the points tensor from the filesystem using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = torch.load('points.t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.]])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with this is the saved tensor can be loaded only with PyTorch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.14 Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor(list(range(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "b =a.view(2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[10,  1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8,  9]])\n",
      "tensor([10,  1,  2,  3,  4,  5,  6,  7,  8,  9])\n"
     ]
    }
   ],
   "source": [
    "b[0,0] = 10\n",
    "print(b)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "same_storage(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10,  1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8,  9]])"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = b[1:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 10\n",
       " 1\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5\n",
       " 6\n",
       " 7\n",
       " 8\n",
       " 9\n",
       "[torch.LongStorage of size 10]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6, 7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4])"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.storage_offset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_sqrt = torch.sqrt(a.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 1.0000, 1.4142, 1.7321, 2.0000, 2.2361, 2.4495, 2.6458, 2.8284,\n",
       "        3.0000])"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 1.0000, 1.4142, 1.7321, 2.0000, 2.2361, 2.4495, 2.6458, 2.8284,\n",
       "        3.0000])"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=a.to(dtype=torch.float32)\n",
    "a.sqrt_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 1.0000, 1.4142, 1.7321, 2.0000, 2.2361, 2.4495, 2.6458, 2.8284,\n",
       "        3.0000])"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
